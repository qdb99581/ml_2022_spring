{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2 Phoneme Classification**\n",
        "\n",
        "* Slides: https://docs.google.com/presentation/d/1v6HkBWiJb8WNDcJ9_-2kwVstxUWml87b9CnA16Gdoio/edit?usp=sharing\n",
        "* Kaggle: https://www.kaggle.com/c/ml2022spring-hw2\n",
        "* Video: TBA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLQI0mNcmM-O",
        "outputId": "d83b2cd4-a2ad-492e-e8df-1517c71b42d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar 13 09:24:58 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:07:00.0  On |                  N/A |\n",
            "|  0%   43C    P5     9W / 100W |   1083MiB /  4096MiB |     27%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1184    C+G                                   N/A      |\n",
            "|    0   N/A  N/A      3180    C+G   ...erver\\YourPhoneServer.exe    N/A      |\n",
            "|    0   N/A  N/A      3836    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      8508    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      8652    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      9064    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A      9516    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     10960    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A     11576    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     11848    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     12020    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     12728    C+G   ...tween\\1.0.8.0\\between.exe    N/A      |\n",
            "|    0   N/A  N/A     12888    C+G   ...5.0.3.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A     13532    C+G   ...LINE\\bin\\current\\LINE.exe    N/A      |\n",
            "|    0   N/A  N/A     13932    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     14052    C+G   ...ram Files\\LGHUB\\lghub.exe    N/A      |\n",
            "|    0   N/A  N/A     16084    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     16224    C+G   ...-2.9.11\\GitHubDesktop.exe    N/A      |\n",
            "|    0   N/A  N/A     16320    C+G   ...s (x86)\\Zotero\\zotero.exe    N/A      |\n",
            "|    0   N/A  N/A     16708    C+G   ...rograms\\Notion\\Notion.exe    N/A      |\n",
            "|    0   N/A  N/A     16728    C+G   ...ll\\1.0.0.403\\LineCall.exe    N/A      |\n",
            "|    0   N/A  N/A     17744    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     19092    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A     19180    C+G   ...Files (x86)\\Anki\\anki.exe    N/A      |\n",
            "|    0   N/A  N/A     23372    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "## Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`\n",
        "- `libriphone/train_labels`\n",
        "- `libriphone/test_split.txt`\n",
        "- `libriphone/feat/train/*.pt`: training feature<br>\n",
        "- `libriphone/feat/test/*.pt`:  testing feature<br>\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the links are dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw2/data) and upload it to the workspace, or you can use [the Kaggle API](https://www.kaggle.com/general/74235) to directly download the data into colab.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5jYXsD9Ef3"
      },
      "source": [
        "### Download train/test metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "08987c17-60a8-4288-875a-a580e3dd9b2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Main link\n",
        "!wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
        "\n",
        "# Backup Link 0\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
        "\n",
        "# Backup link 1\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
        "\n",
        "# Backup link 2\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
        "\n",
        "# Backup link 3\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
        "\n",
        "!unzip -q libriphone.zip\n",
        "!ls libriphone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po4N3C-AWuWl"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n) \n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode != 'test':\n",
        "      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n",
        "\n",
        "      for line in phone_file:\n",
        "          line = line.strip('\\n').split(' ')\n",
        "          label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(train_val_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        percent = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n",
        "    elif split == 'test':\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode != 'test':\n",
        "      y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode != 'test':\n",
        "          label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode != 'test':\n",
        "          y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode != 'test':\n",
        "      y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode != 'test':\n",
        "      print(y.shape)\n",
        "      return X, y\n",
        "    else:\n",
        "      return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bg-GRd7ywdrL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iIHn79Iav1ri"
      },
      "outputs": [],
      "source": [
        "# data prarameters\n",
        "concat_nframes = 25             # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.8               # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# training parameters\n",
        "seed = 0                        # random seed\n",
        "batch_size = 512                # batch size\n",
        "num_epoch = 20                  # the number of training epoch\n",
        "learning_rate = 0.0001          # learning rate\n",
        "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
        "\n",
        "# model parameters\n",
        "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
        "hidden_layers = 8               # the number of hidden layers\n",
        "hidden_dim = 512                # the hidden dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUFRgG5yoDn"
      },
      "source": [
        "## Prepare dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1zI3v5jyrDn",
        "outputId": "310c8f16-cc67-4132-ebd2-32b7c4408db6"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './libriphone\\\\train_labels.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Repos\\Python\\ml_2022_spring\\ML2022Spring_HW2.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgc\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000015?line=2'>3</a>\u001b[0m \u001b[39m# preprocess data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000015?line=3'>4</a>\u001b[0m train_X, train_y \u001b[39m=\u001b[39m preprocess_data(split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, feat_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./libriphone/feat\u001b[39;49m\u001b[39m'\u001b[39;49m, phone_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./libriphone\u001b[39;49m\u001b[39m'\u001b[39;49m, concat_nframes\u001b[39m=\u001b[39;49mconcat_nframes, train_ratio\u001b[39m=\u001b[39;49mtrain_ratio)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000015?line=4'>5</a>\u001b[0m val_X, val_y \u001b[39m=\u001b[39m preprocess_data(split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m, feat_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./libriphone/feat\u001b[39m\u001b[39m'\u001b[39m, phone_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./libriphone\u001b[39m\u001b[39m'\u001b[39m, concat_nframes\u001b[39m=\u001b[39mconcat_nframes, train_ratio\u001b[39m=\u001b[39mtrain_ratio)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000015?line=6'>7</a>\u001b[0m \u001b[39m# get dataset\u001b[39;00m\n",
            "\u001b[1;32md:\\Repos\\Python\\ml_2022_spring\\ML2022Spring_HW2.ipynb Cell 8'\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(split, feat_dir, phone_path, concat_nframes, train_ratio, train_val_seed)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000007?line=41'>42</a>\u001b[0m label_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000007?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000007?line=43'>44</a>\u001b[0m   phone_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(phone_path, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mmode\u001b[39m}\u001b[39;49;00m\u001b[39m_labels.txt\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000007?line=45'>46</a>\u001b[0m   \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m phone_file:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/Python/ml_2022_spring/ML2022Spring_HW2.ipynb#ch0000007?line=46'>47</a>\u001b[0m       line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mstrip(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './libriphone\\\\train_labels.txt'"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfRUEgC0GxUV",
        "outputId": "d334a385-2915-42bb-817e-165f053f0f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88xPiUnm0tAd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#fix seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTp3ZXg1yO9Y"
      },
      "outputs": [],
      "source": [
        "# fix random seed\n",
        "same_seeds(seed)\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWH1KIqzxEr"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMWsBs7zzNs",
        "outputId": "a976da65-998c-4c25-dba8-2a54c9e72ba4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.54it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 118.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/020] Train Acc: 0.462228 Loss: 1.851013 | Val Acc: 0.574333 loss: 1.477411\n",
            "saving model with acc 0.574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.07it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 118.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/020] Train Acc: 0.563764 Loss: 1.453504 | Val Acc: 0.613231 loss: 1.408430\n",
            "saving model with acc 0.613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.04it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/020] Train Acc: 0.593325 Loss: 1.347626 | Val Acc: 0.631202 loss: 1.372119\n",
            "saving model with acc 0.631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.09it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/020] Train Acc: 0.610782 Loss: 1.284787 | Val Acc: 0.643510 loss: 1.345541\n",
            "saving model with acc 0.644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.89it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 116.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/020] Train Acc: 0.622318 Loss: 1.242518 | Val Acc: 0.652805 loss: 1.316949\n",
            "saving model with acc 0.653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.78it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 118.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/020] Train Acc: 0.631780 Loss: 1.209234 | Val Acc: 0.659520 loss: 1.301219\n",
            "saving model with acc 0.660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.96it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/020] Train Acc: 0.639255 Loss: 1.183495 | Val Acc: 0.666837 loss: 1.267334\n",
            "saving model with acc 0.667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.94it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 118.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/020] Train Acc: 0.645165 Loss: 1.161588 | Val Acc: 0.671614 loss: 1.259854\n",
            "saving model with acc 0.672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.84it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/020] Train Acc: 0.650158 Loss: 1.142857 | Val Acc: 0.675646 loss: 1.243545\n",
            "saving model with acc 0.676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.00it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 115.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/020] Train Acc: 0.654583 Loss: 1.126405 | Val Acc: 0.680739 loss: 1.233663\n",
            "saving model with acc 0.681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.84it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[011/020] Train Acc: 0.658529 Loss: 1.113129 | Val Acc: 0.684376 loss: 1.214264\n",
            "saving model with acc 0.684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.18it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 116.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[012/020] Train Acc: 0.661587 Loss: 1.101015 | Val Acc: 0.686788 loss: 1.209513\n",
            "saving model with acc 0.687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.95it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[013/020] Train Acc: 0.665138 Loss: 1.089414 | Val Acc: 0.691330 loss: 1.180618\n",
            "saving model with acc 0.691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.15it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 116.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[014/020] Train Acc: 0.668151 Loss: 1.080774 | Val Acc: 0.693619 loss: 1.181007\n",
            "saving model with acc 0.694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.52it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[015/020] Train Acc: 0.670355 Loss: 1.070948 | Val Acc: 0.695699 loss: 1.177359\n",
            "saving model with acc 0.696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.03it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 117.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[016/020] Train Acc: 0.672850 Loss: 1.062759 | Val Acc: 0.697698 loss: 1.169121\n",
            "saving model with acc 0.698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:33<00:00, 44.02it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 116.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[017/020] Train Acc: 0.674888 Loss: 1.055188 | Val Acc: 0.700949 loss: 1.157141\n",
            "saving model with acc 0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.94it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 115.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[018/020] Train Acc: 0.677167 Loss: 1.047875 | Val Acc: 0.702492 loss: 1.147821\n",
            "saving model with acc 0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.80it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 116.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[019/020] Train Acc: 0.678507 Loss: 1.041999 | Val Acc: 0.702618 loss: 1.153802\n",
            "saving model with acc 0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4134/4134 [01:34<00:00, 43.90it/s]\n",
            "100%|██████████| 1031/1031 [00:08<00:00, 116.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[020/020] Train Acc: 0.680306 Loss: 1.036098 | Val Acc: 0.705737 loss: 1.124737\n",
            "saving model with acc 0.706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(features) \n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        \n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(tqdm(val_loader)):\n",
        "                features, labels = batch\n",
        "                features = features.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(features)\n",
        "                \n",
        "                loss = criterion(outputs, labels) \n",
        "                \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab33MxosWLmG",
        "outputId": "3a2a8119-3c6e-4a76-a5a2-d43046f0e552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del train_loader, val_loader\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOG1Ou0PGrhc",
        "outputId": "4e19e54e-e238-45f4-d7da-71087422c68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "301it [00:02, 122.40it/s]"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay0Fu8Ovkdad"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84HU5GGjPqR0"
      },
      "outputs": [],
      "source": [
        "test_acc = 0.0\n",
        "test_lengths = 0\n",
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = features.to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ML2022Spring - HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
